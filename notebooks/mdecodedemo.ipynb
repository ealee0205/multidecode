{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a simple implementation of the MultiDecode algorithm.  In this notebook the attention masks and position_ids are generated manually and then passed to mdgen for iterative token generation.  A few simple examples are demonstrated. \n",
    "- beam search\n",
    "- parallel questions\n",
    "- writing in the margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import copy\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,AutoConfig\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to Hugging Face\n",
    "\n",
    "from huggingface_hub import login\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    hf_token=userdata.get('huggingface')\n",
    "except:\n",
    "    import os\n",
    "    import dotenv\n",
    "    dotenv.load_dotenv(\"../.env\")\n",
    "    hf_token=os.getenv('HUGGINGFACE')\n",
    "\n",
    "\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdgen(model, input_ids,positions=None,mask=None,gen_len=10,n_branch=2,greedy=False,branch_locations=None,past_key_values=None):\n",
    "    \"\"\"\n",
    "    Implements the parallel generation of tokens using the multidecode technique.\n",
    "\n",
    "    This function generates tokens in parallel by branching at specified positions in the input sequence.\n",
    "    It uses a model's forward pass to compute logits and generate tokens iteratively, either greedily or\n",
    "    through sampling. The generated tokens are accumulated and returned along with other relevant data.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model used for token generation. Must support `forward` with caching.\n",
    "        input_ids (torch.Tensor): Input token IDs of shape (batch_size, ctx_len).\n",
    "        positions (torch.Tensor, optional): Position encodings for the input tokens. If None, defaults to\n",
    "            sequential positions [0, 1, ..., ctx_len-1]. Shape must match `input_ids`.\n",
    "        mask (torch.Tensor): Attention mask of shape (batch_size, ctx_len, ctx_len). Controls which tokens\n",
    "            the model attends to during prefill.\n",
    "        gen_len (int, optional): Number of tokens to generate. Defaults to 10.\n",
    "        n_branch (int, optional): Number of parallel branches for token generation. Defaults to 2.\n",
    "        greedy (bool, optional): If True, selects the most probable token at each step. If False, samples\n",
    "            tokens based on probabilities. Defaults to False.\n",
    "        branch_locations (list, optional): List of positions where branches start. If None, defaults to\n",
    "            the end of the input context.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'branch_ids' (torch.Tensor): Generated token IDs for each branch, reshaped to (n_branch, batch_size).\n",
    "            - 'mask' (torch.Tensor): Final attention mask after generation.\n",
    "            - 'output_ids' (torch.Tensor): All generated token IDs concatenated sequentially.\n",
    "            - 'input_ids' (torch.Tensor): Original input token IDs.\n",
    "            - 'positions' (torch.Tensor): Position encodings for all tokens, including generated ones.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If `positions` shape does not match `input_ids` shape.\n",
    "\n",
    "    Example:\n",
    "        output = mdgen(\n",
    "            model=my_model,\n",
    "            input_ids=torch.tensor([[1, 2, 3]]),\n",
    "            mask=torch.ones(1, 3, 3),\n",
    "            gen_len=5,\n",
    "            n_branch=2,\n",
    "            greedy=True\n",
    "        )\n",
    "        print(output['branch_ids'])\n",
    "    \"\"\"\n",
    "\n",
    "    past_len=0 if past_key_values is None else past_key_values.get_seq_length()\n",
    "\n",
    "    if positions is not None:\n",
    "        assert input_ids.shape == positions.shape,\"positions.shape must match input_ids.shape\"\n",
    "    #assert mask.shape[2]==input_ids.shape[1],\"length of attn mask must match input length\"\n",
    "\n",
    "\n",
    "    batch_size,ctx_len=input_ids.shape\n",
    "    \n",
    "    # every cycle we add n_branch more tokens, so the end of the 4D attention mask is a diagonal. Create here and reuse below\n",
    "    gen_mask = torch.where(torch.eye(n_branch) == 1, torch.tensor(0.0), torch.tensor(float('-inf'))).unsqueeze(0).unsqueeze(0).to(model.device)\n",
    "\n",
    "    # position information of the initial context input_ids. If None assume 0..ctx_len\n",
    "    if positions is None:\n",
    "        positions=torch.arange(ctx_len,dtype=torch.int).unsqueeze(0)\n",
    "    positions=positions.to(model.device)\n",
    "    position_history=copy.copy(positions)\n",
    "\n",
    "\n",
    "    # if branch location is not specified, assume all branches start at the end of the context\n",
    "    if branch_locations is None:\n",
    "        branch_locations=[ctx_len-1]*n_branch\n",
    "        \n",
    "    assert all(bl>past_len for bl in branch_locations),\"Branches must start with new input_ids, not from past_key_values.\"\n",
    "\n",
    "    # the position encoding of the first generated token is just after the branch location position encoding\n",
    "    tmp=[int(positions[0,x]) for x in branch_locations] \n",
    "    gen_positions=torch.tensor(tmp).unsqueeze(0).to(model.device)\n",
    "\n",
    "\n",
    "    # we will accumulate the generated tokens into output_ids\n",
    "    output_ids=torch.empty((batch_size,0),dtype=torch.int).to(model.device)\n",
    "\n",
    "    # move remaining tensors to model.device\n",
    "    mask=mask.to(model.device)\n",
    "    input_ids=input_ids.to(model.device)\n",
    "    initial_length=input_ids.shape[1]\n",
    "    pkv=past_key_values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # first step is to prefill the context and generate pkv\n",
    "        output=model.forward(input_ids=input_ids[:,past_len:],position_ids=positions[:,past_len:] ,attention_mask=mask, use_cache=True,past_key_values=pkv)\n",
    "        pkv = output.past_key_values\n",
    "\n",
    "        # get logits from the locations where the branches fork\n",
    "        branch_locations=torch.tensor(branch_locations,dtype=torch.int)\n",
    "        \n",
    "        # branch locations are relative to full input sequence,\n",
    "        # so we subtrack the pkv length \n",
    "        logits=output['logits'][:,branch_locations-past_len,:]\n",
    "        mask = mask[:,:,branch_locations-past_len,:]\n",
    "\n",
    "        for i in range(gen_len):\n",
    "            # select tokens, greedy or not\n",
    "            next_token_probs = F.softmax(logits / 0.7, dim=-1)\n",
    "            if greedy:\n",
    "                tokens = torch.argmax(next_token_probs,dim=-1)\n",
    "            else:\n",
    "                samples = torch.multinomial(next_token_probs.view(-1,next_token_probs.shape[-1]), num_samples=1, replacement=True).view(batch_size,n_branch)\n",
    "                tokens = samples.squeeze(-1)\n",
    "\n",
    "            # save the generated tokens\n",
    "            output_ids=torch.cat([output_ids,tokens],dim=-1)\n",
    "            mask=torch.cat([mask,gen_mask],dim=-1)\n",
    "\n",
    "            # Generate n_branch new tokens.\n",
    "            output=model.forward(input_ids=tokens,position_ids=gen_positions ,attention_mask=mask, past_key_values=pkv, use_cache=True)\n",
    "            logits=output['logits']\n",
    "            pkv = output['past_key_values'] \n",
    "\n",
    "            # increment the position information for the next token\n",
    "            gen_positions+=1\n",
    "\n",
    "            position_history=torch.cat([position_history,gen_positions],dim=-1)\n",
    "\n",
    "    # restruture the results to have n_branch sequences\n",
    "    branch_ids=output_ids.view(-1,n_branch,1).permute(2,1,0).squeeze(-1)\n",
    "    full_ids=torch.cat([input_ids,output_ids],dim=-1)\n",
    "    return {'branch_ids':branch_ids,'mask':mask,'output_ids':output_ids,'input_ids':full_ids,\n",
    "            'n_branch':n_branch,'initial_length':initial_length,'positions':position_history,'past_key_values':pkv}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpful utilities\n",
    "def print_branches(branch_ids):\n",
    "    branch_ids=branch_ids.cpu()\n",
    "    for sidx,branches in enumerate(branch_ids):\n",
    "        for bidx,branch_ids in enumerate(branches):\n",
    "            ids=branch_ids\n",
    "            print(f\"{sidx}.{bidx}: {''.join(tokenizer.batch_decode(ids, skip_special_tokens=True))}\")\n",
    "\n",
    "def print_mask(mask):\n",
    "    for i in range(mask.shape[2]):\n",
    "        for j in range(mask.shape[3]):\n",
    "            print('*' if mask[0,0,i,j]==0. else '.',end=\"\")\n",
    "        print()\n",
    "\n",
    "def print_full(output):\n",
    "    full_ids=torch.cat([output['input_ids'],output['output_ids']],dim=-1)\n",
    "    # print(f\"{full_ids=}\")\n",
    "    # print(''.join(tokenizer.batch_decode(full_ids, skip_special_tokens=True)))\n",
    "    mask=output['mask']\n",
    "    for b in range(mask.shape[2]):\n",
    "        branch_full_ids=[]\n",
    "        for p in range(mask.shape[3]):\n",
    "            if mask[0,0,b,p] == 0.0:\n",
    "                branch_full_ids.append(int(full_ids[0,p]))\n",
    "        print(f\"{b}:{''.join(tokenizer.batch_decode(branch_full_ids, skip_special_tokens=True))}\")\n",
    "        \n",
    "\n",
    "def print_args(input_ids=None,positions=None,mask=None,branch_locations=None):\n",
    "    print()\n",
    "    print(\"Arguments:\")\n",
    "    print(f\"{input_ids.shape=}\")\n",
    "    if positions is not None:\n",
    "        print(f\"{positions=}\")\n",
    "    if branch_locations is not None:\n",
    "        print(f\"{branch_locations=}\")\n",
    "    print()\n",
    "    if mask is not None:\n",
    "        print_mask(mask)\n",
    "    print()\n",
    "\n",
    "def print_results(output):\n",
    "    print()\n",
    "    print(\"Results\")\n",
    "    print(\"raw\")\n",
    "    print(f\"{''.join(tokenizer.batch_decode(output['output_ids'], skip_special_tokens=True))}\")\n",
    "    print()\n",
    "    print(\"Reformated\")\n",
    "    print_full(output)\n",
    "    print()\n",
    "    print(f\"positions {output['positions']}\")\n",
    "    print()\n",
    "    print_mask(output['mask'])\n",
    "    print()\n",
    "    \n",
    "def strmask(*args):\n",
    "    n_branch=len(args)\n",
    "    seq_len=len(args[0])\n",
    "    ret=torch.full((n_branch,seq_len),fill_value=float('-inf'))\n",
    "\n",
    "    for b,arg in enumerate(args):\n",
    "        for i,v in enumerate(arg):\n",
    "            if v=='1' or v=='*':\n",
    "                ret[b,i]=0\n",
    "    return ret.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "def lut_attn(n):\n",
    "    ''''\n",
    "\n",
    "    Returns a lower triangle array with dimensions and values suitable for an attention mask\n",
    "    dimension: [1,1,n,n]\n",
    "    values: 0 in lower triangle and diagonal\n",
    "            -inf in upper triangle\n",
    "    \n",
    "    '''\n",
    "    return torch.where(torch.tril(torch.ones(n,n)) == 1, torch.tensor(0.0), torch.tensor(float('-inf'))).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "model_name=\"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,padding_side='left')\n",
    "tokenizer.pad_token_id=tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)#,attn_implementation=\"flex_attention\")\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 5])\n",
      "\n",
      "*....\n",
      "**...\n",
      "***..\n",
      "****.\n",
      "*****\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      ",,,, there there there there in was was was was the a a a a middle little young man woman of girl woman called called  called named Bl S198 Ting Kaiseall0aik Pascalies,uko..\n",
      ", she\n",
      "\n",
      "Reformated\n",
      "0:Once upon a time, there was a young woman named Kikuko\n",
      "1:Once upon a time, there was a man called Blaise Pascal.\n",
      "2:Once upon a time, there was a woman called Sallie.\n",
      "\n",
      "3:Once upon a time, in the middle of 1980s,\n",
      "4:Once upon a time there was a little girl called Tinga, she\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  7,  7,  7,\n",
      "          7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 11,\n",
      "         11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14,\n",
      "         14]], device='cuda:0')\n",
      "\n",
      "******....*....*....*....*....*....*....*....*....*....\n",
      "*****.*....*....*....*....*....*....*....*....*....*...\n",
      "*****..*....*....*....*....*....*....*....*....*....*..\n",
      "*****...*....*....*....*....*....*....*....*....*....*.\n",
      "*****....*....*....*....*....*....*....*....*....*....*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# simple beam generation\n",
    "input_ids=tokenizer(\"Once upon a time\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "\n",
    "print_args(input_ids,mask=mask)\n",
    "\n",
    "output=mdgen(model, input_ids,positions=None,mask=mask,n_branch=5,greedy=False)\n",
    "\n",
    "print_results(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_branch(output,selected_branch):\n",
    "    \"\"\"\n",
    "    Selects a specific branch from the output of the `mdgen` function.\n",
    "\n",
    "    This function extracts the input IDs, position IDs, attention mask, and past key values\n",
    "    corresponding to the specified branch index from the output of the `mdgen` function.\n",
    "\n",
    "    Args:\n",
    "        output (dict): The output dictionary from the `mdgen` function. It should contain:\n",
    "            - 'branch_ids' (torch.Tensor): Generated token IDs for each branch.\n",
    "            - 'positions' (torch.Tensor): Position encodings for each branch.\n",
    "            - 'mask' (torch.Tensor): Attention mask for each branch.\n",
    "            - 'past_key_values' (optional): Cached key-value pairs for efficient decoding.\n",
    "        branch_index (int): The index of the branch to select.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - input2_ids (torch.Tensor): The token IDs for the selected branch.\n",
    "            - position2_ids (torch.Tensor): The position encodings for the selected branch.\n",
    "            - mask2 (torch.Tensor): The attention mask for the selected branch.\n",
    "            - pkv (optional): The past key-value pairs for the selected branch, if available.\n",
    "\n",
    "    Raises:\n",
    "        IndexError: If the specified branch index is out of range.\n",
    "\n",
    "    Example:\n",
    "        input2_ids, position2_ids, mask2, pkv = select_branch(output, branch_index=1)\n",
    "    \"\"\"\n",
    "    pkv=output['past_key_values']\n",
    "    o_positions=output['positions']\n",
    "    o_mask=output['mask']\n",
    "    o_input_ids=output['input_ids']\n",
    "    o_initial_len=output['initial_length']\n",
    "    o_input_ids_len=o_input_ids.shape[1]\n",
    "    n_branch=output['n_branch']\n",
    "\n",
    "    input_indexes=torch.cat([torch.arange(o_initial_len),torch.arange(o_initial_len+selected_branch,o_input_ids_len+1,n_branch,dtype=torch.int)],dim=-1)\n",
    "\n",
    "    input2_ids=o_input_ids[:,input_indexes]\n",
    "    position2_ids=o_positions[:,input_indexes]\n",
    "    selected_len=(o_input_ids.shape[1]- o_initial_len)//n_branch\n",
    "    mask2=o_mask[:,:,selected_branch,input_indexes[:o_initial_len]].repeat([1,1,selected_len,1])\n",
    "    mask2=torch.cat([mask2,lut_attn(selected_len).to(model.device)],dim=-1)\n",
    "\n",
    "    pkv.crop(o_initial_len)\n",
    "\n",
    "    print(f\"{input2_ids.shape=} {position2_ids.shape=} {mask2.shape=} {pkv.get_seq_length()=}\")\n",
    "    return input2_ids,position2_ids, mask2, pkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 5])\n",
      "\n",
      "*....\n",
      "**...\n",
      "***..\n",
      "****.\n",
      "*****\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      ",, I in there was a was a very a man different girl. place called I, Grace was there. a was Grace Publisher a had and\n",
      "\n",
      "Reformated\n",
      "0:Once upon a time, in a very different place, there was a\n",
      "1:Once upon a time, there was a girl called Grace. Grace had\n",
      "2:Once upon a time I was a man. I was a Publisher and\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,\n",
      "          9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14]],\n",
      "       device='cuda:0')\n",
      "\n",
      "******..*..*..*..*..*..*..*..*..*..\n",
      "*****.*..*..*..*..*..*..*..*..*..*.\n",
      "*****..*..*..*..*..*..*..*..*..*..*\n",
      "\n",
      "input2_ids.shape=torch.Size([1, 15]) position2_ids.shape=torch.Size([1, 15]) mask2.shape=torch.Size([1, 1, 10, 15]) pkv.get_seq_length()=5\n",
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 15])\n",
      "positions=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]],\n",
      "       device='cuda:0')\n",
      "\n",
      "******.........\n",
      "*******........\n",
      "********.......\n",
      "*********......\n",
      "**********.....\n",
      "***********....\n",
      "************...\n",
      "*************..\n",
      "**************.\n",
      "***************\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      " been been the a a most very friend beautiful happy of eyes girl mine.. for The She several colour grew years of up, her in and eyes\n",
      "\n",
      "Reformated\n",
      "0:Once upon a time, there was a girl called Grace. Grace had been a very happy girl. She grew up in\n",
      "1:Once upon a time, there was a girl called Grace. Grace had been a friend of mine for several years, and\n",
      "2:Once upon a time, there was a girl called Grace. Grace had the most beautiful eyes. The colour of her eyes\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 15, 15,\n",
      "         16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21,\n",
      "         22, 22, 22, 23, 23, 23, 24, 24, 24]], device='cuda:0')\n",
      "\n",
      "****************..*..*..*..*..*..*..*..*..*..\n",
      "***************.*..*..*..*..*..*..*..*..*..*.\n",
      "***************..*..*..*..*..*..*..*..*..*..*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example for using the select branch function\n",
    "\n",
    "input_ids=tokenizer(\"Once upon a time\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "\n",
    "print_args(input_ids,mask=mask)\n",
    "\n",
    "input_len=input_ids.shape[1]\n",
    "n_branch=3\n",
    "output=mdgen(model, input_ids,positions=None,mask=mask,n_branch=n_branch,greedy=False)\n",
    "print_results(output)\n",
    "selected_branch=1\n",
    "\n",
    "\n",
    "\n",
    "input2_ids,position2_ids,mask2, pkv=select_branch(output,1)\n",
    "\n",
    "print_args(input2_ids,positions=position2_ids,mask=mask2)\n",
    "\n",
    "output=mdgen(model, input2_ids,positions=position2_ids,mask=mask2,n_branch=n_branch,greedy=False,past_key_values=pkv)\n",
    "\n",
    "print_results(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 31])\n",
      "positions=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 17, 18, 19, 20, 21, 22, 23]])\n",
      "\n",
      "*..............................\n",
      "**.............................\n",
      "***............................\n",
      "****...........................\n",
      "*****..........................\n",
      "******.........................\n",
      "*******........................\n",
      "********.......................\n",
      "*********......................\n",
      "**********.....................\n",
      "***********....................\n",
      "************...................\n",
      "*************..................\n",
      "**************.................\n",
      "***************................\n",
      "****************...............\n",
      "*****************..............\n",
      "******************.............\n",
      "*******************............\n",
      "********************...........\n",
      "*********************..........\n",
      "**********************.........\n",
      "***********************........\n",
      "************************.......\n",
      "*****************.......*......\n",
      "*****************.......**.....\n",
      "*****************.......***....\n",
      "*****************.......****...\n",
      "*****************.......*****..\n",
      "*****************.......******.\n",
      "*****************.......*******\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      " The The answer answer is is purple green.. The The bike grass is is purple green..\n",
      "\n",
      "Reformated\n",
      "0:The house is red. The grass is green. The bike is purple. What color is the bike? The answer is purple. The bike is purple.\n",
      "1:The house is red. The grass is green. The bike is purple. What color is the grass? The answer is green. The grass is green.\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 25, 26,\n",
      "         26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32, 32, 33, 33]],\n",
      "       device='cuda:0')\n",
      "\n",
      "************************.......*.*.*.*.*.*.*.*.*.*.\n",
      "*****************.......*******.*.*.*.*.*.*.*.*.*.*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multi-question\n",
    "context_ids=tokenizer(\"The house is red. The grass is green. The bike is purple. \", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device) \n",
    "question1_ids=tokenizer(\"What color is the bike?\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "question2_ids=tokenizer(\"What color is the grass?\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "context_len=context_ids.shape[1]\n",
    "question1_len=question1_ids.shape[1]\n",
    "question2_len=question2_ids.shape[1]\n",
    "\n",
    "input_ids=torch.cat([context_ids,question1_ids,question2_ids],dim=-1)\n",
    "\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "# mask out the first question from the view of the second question\n",
    "mask[:,:,context_len+question1_len:,context_len:context_len+question1_len]=float('-inf')\n",
    "\n",
    "positions=torch.cat([torch.arange(context_len+question1_len),torch.arange(context_len,context_len+question2_len)]).unsqueeze(0)\n",
    "branch_locations=[context_len+question1_len-1,context_len+question1_len+question2_len-1]\n",
    "\n",
    "print_args(input_ids,positions,mask)\n",
    "\n",
    "output=mdgen(model, input_ids,positions=positions,mask=mask,branch_locations=branch_locations,greedy=True)\n",
    "\n",
    "print_results(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context1_len=7 context2_len=12 question1_len=7 question2_len=7\n",
      "positions=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18,  7,  8,  9, 10, 11, 12, 13, 19, 20, 21, 22, 23, 24, 25]])\n",
      "input_ids.shape=torch.Size([1, 33]) positions.shape=torch.Size([1, 33])\n",
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 33])\n",
      "positions=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18,  7,  8,  9, 10, 11, 12, 13, 19, 20, 21, 22, 23, 24, 25]])\n",
      "\n",
      "*................................\n",
      "**...............................\n",
      "***..............................\n",
      "****.............................\n",
      "*****............................\n",
      "******...........................\n",
      "*******..........................\n",
      "********.........................\n",
      "*********........................\n",
      "**********.......................\n",
      "***********......................\n",
      "************.....................\n",
      "*************....................\n",
      "**************...................\n",
      "***************..................\n",
      "****************.................\n",
      "*****************................\n",
      "******************...............\n",
      "*******************..............\n",
      "*******............*.............\n",
      "*******............**............\n",
      "*******............***...........\n",
      "*******............****..........\n",
      "*******............*****.........\n",
      "*******............******........\n",
      "*******............*******.......\n",
      "*******************.......*......\n",
      "*******************.......**.....\n",
      "*******************.......***....\n",
      "*******************.......****...\n",
      "*******************.......*****..\n",
      "*******************.......******.\n",
      "*******************.......*******\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      " The The house answer was is red blue..  The2 house. is What red color.\n",
      "\n",
      "Reformated\n",
      "0:The house was red. What color is the bike? The house was red. 2. What color\n",
      "1:The house was red. The grass was green. The bike was blue. What color is the bike? The answer is blue. The house is red.\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18,  7,  8,  9, 10, 11, 12, 13, 19, 20, 21, 22, 23, 24, 25, 14, 26, 15,\n",
      "         27, 16, 28, 17, 29, 18, 30, 19, 31, 20, 32, 21, 33, 22, 34, 23, 35]],\n",
      "       device='cuda:0')\n",
      "\n",
      "*******............*******.......*.*.*.*.*.*.*.*.*.*.\n",
      "*******************.......*******.*.*.*.*.*.*.*.*.*.*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Writing in the margins\n",
    "context1_ids=tokenizer(\"The house was red. \", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "context2_ids=tokenizer(\"The grass was green. The bike was blue. \", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)  \n",
    "question1_ids=tokenizer(\"What color is the bike?\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "question2_ids=tokenizer(\"What color is the bike?\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "context1_len=context1_ids.shape[1]\n",
    "context2_len=context2_ids.shape[1]\n",
    "question1_len=question1_ids.shape[1]\n",
    "question2_len=question2_ids.shape[1]\n",
    "print(f\"{context1_len=} {context2_len=} {question1_len=} {question2_len=}\")\n",
    "\n",
    "input_ids=torch.cat([context1_ids,context2_ids,question1_ids,question2_ids],dim=-1)\n",
    "\n",
    "# mask out the second context from the first question, and the first question from the view of the second question\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "mask[:,:,context1_len+context2_len:context1_len+context2_len+question1_len,context1_len:context1_len+context2_len]=float('-inf')\n",
    "mask[:,:,context1_len+context2_len+question1_len:,context1_len+context2_len:context1_len+context2_len+question1_len]=float('-inf')\n",
    "\n",
    "\n",
    "# make question 1 follow context1 and question 2 follow context2 \n",
    "positions=torch.cat([\n",
    "    torch.arange(context1_len+context2_len),\n",
    "    torch.arange(context1_len,context1_len+question1_len),\n",
    "    torch.arange(context1_len+context2_len,context1_len+context2_len+question2_len)]).unsqueeze(0)\n",
    "\n",
    "print(f\"{positions=}\")\n",
    "print(f\"{input_ids.shape=} {positions.shape=}\")\n",
    "branch_locations=[context1_len+context2_len+question1_len-1,context1_len+context2_len+question1_len+question2_len-1]\n",
    "\n",
    "print_args(input_ids,positions,mask)\n",
    "\n",
    "output=mdgen(model, input_ids,positions=positions,mask=mask,branch_locations=branch_locations,greedy=True)\n",
    "\n",
    "print_results(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 6])\n",
      "\n",
      "*.....\n",
      "**....\n",
      "***...\n",
      "****..\n",
      "*****.\n",
      "******\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      " 2\n",
      "\n",
      "Reformated\n",
      "0:5 - 3 = 2\n",
      "\n",
      "positions tensor([[0, 1, 2, 3, 4, 5, 6, 7]], device='cuda:0')\n",
      "\n",
      "********\n",
      "\n",
      "0:5 - 3 = 2\n"
     ]
    }
   ],
   "source": [
    "# Teds example part 1\n",
    "input_ids=tokenizer(\"5 - 3 =\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "\n",
    "print_args(input_ids,mask=mask)\n",
    "\n",
    "output=mdgen(model, input_ids,mask=mask,n_branch=1,gen_len=2,greedy=True)\n",
    "\n",
    "print_results(output)\n",
    "print_full(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_ids.cpu()=tensor([[128000,     20,    482,    220,     18,    284]])\n",
      "input_ids.cpu()=tensor([[128000,     20,    284,    482,    220,     18]])\n",
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 6])\n",
      "positions=tensor([[0, 1, 5, 2, 3, 4]], dtype=torch.int32)\n",
      "\n",
      "*.....\n",
      "**....\n",
      "******\n",
      "**.*..\n",
      "**.**.\n",
      "**.***\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      " 2\n",
      "\n",
      "Reformated\n",
      "0:5 = - 3 2\n",
      "\n",
      "positions tensor([[0, 1, 5, 2, 3, 4, 6, 7]], device='cuda:0')\n",
      "\n",
      "********\n",
      "\n",
      "0:5 = - 3 2\n"
     ]
    }
   ],
   "source": [
    "# Teds example part 2\n",
    "original_ids=tokenizer(\"5 - 3 =\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "print(f\"{original_ids.cpu()=}\")\n",
    "input_ids=tokenizer(\"5 = - 3\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "print(f\"{input_ids.cpu()=}\")\n",
    "\n",
    "\n",
    "mask=strmask(\"*.....\",\"**....\",\"******\",\"**.*..\",\"**.**.\",\"**.***\")\n",
    "\n",
    "order=torch.tensor([0, 1, 3, 4, 5, 2])\n",
    "\n",
    "positions=torch.tensor([[0, 1, 5, 2,3,4]],dtype=torch.int)\n",
    "branch_locations=[2]\n",
    "\n",
    "print_args(input_ids,mask=mask,positions=positions)\n",
    "\n",
    "output=mdgen(model, input_ids,positions=positions,mask=mask,branch_locations=branch_locations,n_branch=1,gen_len=2,greedy=True)\n",
    "\n",
    "print_results(output)\n",
    "print_full(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_branch(output,selected_branch):\n",
    "    \"\"\"\n",
    "    Selects a specific branch from the output of the `mdgen` function.\n",
    "\n",
    "    This function extracts the input IDs, position IDs, attention mask, and past key values\n",
    "    corresponding to the specified branch index from the output of the `mdgen` function.\n",
    "\n",
    "    Args:\n",
    "        output (dict): The output dictionary from the `mdgen` function. It should contain:\n",
    "            - 'branch_ids' (torch.Tensor): Generated token IDs for each branch.\n",
    "            - 'positions' (torch.Tensor): Position encodings for each branch.\n",
    "            - 'mask' (torch.Tensor): Attention mask for each branch.\n",
    "            - 'past_key_values' (optional): Cached key-value pairs for efficient decoding.\n",
    "        branch_index (int): The index of the branch to select.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - input2_ids (torch.Tensor): The token IDs for the selected branch.\n",
    "            - position2_ids (torch.Tensor): The position encodings for the selected branch.\n",
    "            - mask2 (torch.Tensor): The attention mask for the selected branch.\n",
    "            - pkv (optional): The past key-value pairs for the selected branch, if available.\n",
    "\n",
    "    Raises:\n",
    "        IndexError: If the specified branch index is out of range.\n",
    "\n",
    "    Example:\n",
    "        input2_ids, position2_ids, mask2, pkv = select_branch(output, branch_index=1)\n",
    "    \"\"\"\n",
    "    pkv=output['past_key_values']\n",
    "    o_positions=output['positions']\n",
    "    o_mask=output['mask']\n",
    "    o_input_ids=output['input_ids']\n",
    "    o_initial_len=output['initial_length']\n",
    "    o_input_ids_len=o_input_ids.shape[1]\n",
    "\n",
    "    input_indexes=torch.cat([torch.arange(o_initial_len),torch.arange(o_initial_len+selected_branch,o_input_ids_len+1,n_branch,dtype=torch.int)],dim=-1)\n",
    "\n",
    "    input2_ids=o_input_ids[:,input_indexes]\n",
    "    position2_ids=o_positions[:,input_indexes]\n",
    "    selected_len=(o_input_ids.shape[1]- o_initial_len)//n_branch\n",
    "    mask2=o_mask[:,:,selected_branch,input_indexes[:o_initial_len]].repeat([1,1,selected_len,1])\n",
    "    mask2=torch.cat([mask2,lut_attn(selected_len).to(model.device)],dim=-1)\n",
    "\n",
    "    pkv.crop(o_initial_len)\n",
    "\n",
    "    print(f\"{input2_ids.shape=} {position2_ids.shape=} {mask2.shape=} {pkv.get_seq_length()=}\")\n",
    "    return input2_ids,position2_ids, mask2, pkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 5])\n",
      "\n",
      "*....\n",
      "**...\n",
      "***..\n",
      "****.\n",
      "*****\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results\n",
      "raw\n",
      " in, there the a was world long a of time little Architecture ago girl and,, fashion there who, was would two a have of farmer been\n",
      "\n",
      "Reformated\n",
      "0:Once upon a time in the world of Architecture and fashion, two of\n",
      "1:Once upon a time, a long time ago, there was a farmer\n",
      "2:Once upon a time there was a little girl, who would have been\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,\n",
      "          9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14]],\n",
      "       device='cuda:0')\n",
      "\n",
      "******..*..*..*..*..*..*..*..*..*..\n",
      "*****.*..*..*..*..*..*..*..*..*..*.\n",
      "*****..*..*..*..*..*..*..*..*..*..*\n",
      "\n",
      "input2_ids.shape=torch.Size([1, 15]) position2_ids.shape=torch.Size([1, 15]) mask2.shape=torch.Size([1, 1, 10, 15]) pkv.get_seq_length()=5\n",
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 15])\n",
      "positions=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]],\n",
      "       device='cuda:0')\n",
      "\n",
      "******.........\n",
      "*******........\n",
      "********.......\n",
      "*********......\n",
      "**********.....\n",
      "***********....\n",
      "************...\n",
      "*************..\n",
      "**************.\n",
      "***************\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      " who who who went was had to very a the hungry very market. large and He, bought was very a a hungry cow very cow. big.\n",
      "\n",
      "Reformated\n",
      "0:Once upon a time, a long time ago, there was a farmer who went to the market and bought a cow.\n",
      "1:Once upon a time, a long time ago, there was a farmer who was very hungry. He was a very big\n",
      "2:Once upon a time, a long time ago, there was a farmer who had a very large, very hungry cow.\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 15, 15,\n",
      "         16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21,\n",
      "         22, 22, 22, 23, 23, 23, 24, 24, 24]], device='cuda:0')\n",
      "\n",
      "****************..*..*..*..*..*..*..*..*..*..\n",
      "***************.*..*..*..*..*..*..*..*..*..*.\n",
      "***************..*..*..*..*..*..*..*..*..*..*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example for using the select branch function\n",
    "\n",
    "input_ids=tokenizer(\"Once upon a time\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "\n",
    "print_args(input_ids,mask=mask)\n",
    "\n",
    "input_len=input_ids.shape[1]\n",
    "n_branch=3\n",
    "output=mdgen(model, input_ids,positions=None,mask=mask,n_branch=n_branch,greedy=False)\n",
    "print_results(output)\n",
    "selected_branch=1\n",
    "\n",
    "\n",
    "\n",
    "input2_ids,position2_ids,mask2, pkv=select_branch(output,1)\n",
    "\n",
    "print_args(input2_ids,positions=position2_ids,mask=mask2)\n",
    "\n",
    "output=mdgen(model, input2_ids,positions=position2_ids,mask=mask2,n_branch=n_branch,greedy=False,past_key_values=pkv)\n",
    "\n",
    "print_results(output)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
