{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a simple implementation of the MultiDecode algorithm.  In this notebook the attention masks and position_ids are generated manually and then passed to mdgen for iterative token generation.  A few simple examples are demonstrated. \n",
    "- beam search\n",
    "- parallel questions\n",
    "- writing in the margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import copy\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,AutoConfig\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to Hugging Face\n",
    "\n",
    "from huggingface_hub import login\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    hf_token=userdata.get('huggingface')\n",
    "except:\n",
    "    import os\n",
    "    import dotenv\n",
    "    dotenv.load_dotenv(\"../.env\")\n",
    "    hf_token=os.getenv('HUGGINGFACE')\n",
    "\n",
    "\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdgen(model, input_ids,positions=None,mask=None,gen_len=10,n_branch=2,greedy=False,branch_locations=None,past_key_values=None):\n",
    "    \"\"\"\n",
    "    Implements the parallel generation of tokens using the multidecode technique.\n",
    "\n",
    "    This function generates tokens in parallel by branching at specified positions in the input sequence.\n",
    "    It uses a model's forward pass to compute logits and generate tokens iteratively, either greedily or\n",
    "    through sampling. The generated tokens are accumulated and returned along with other relevant data.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model used for token generation. Must support `forward` with caching.\n",
    "        input_ids (torch.Tensor): Input token IDs of shape (batch_size, ctx_len).\n",
    "        positions (torch.Tensor, optional): Position encodings for the input tokens. If None, defaults to\n",
    "            sequential positions [0, 1, ..., ctx_len-1]. Shape must match `input_ids`.\n",
    "        mask (torch.Tensor): Attention mask of shape (batch_size, ctx_len, ctx_len). Controls which tokens\n",
    "            the model attends to during prefill.\n",
    "        gen_len (int, optional): Number of tokens to generate. Defaults to 10.\n",
    "        n_branch (int, optional): Number of parallel branches for token generation. Defaults to 2.\n",
    "        greedy (bool, optional): If True, selects the most probable token at each step. If False, samples\n",
    "            tokens based on probabilities. Defaults to False.\n",
    "        branch_locations (list, optional): List of positions where branches start. If None, defaults to\n",
    "            the end of the input context.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'branch_ids' (torch.Tensor): Generated token IDs for each branch, reshaped to (n_branch, batch_size).\n",
    "            - 'mask' (torch.Tensor): Final attention mask after generation.\n",
    "            - 'output_ids' (torch.Tensor): All generated token IDs concatenated sequentially.\n",
    "            - 'input_ids' (torch.Tensor): Original input token IDs.\n",
    "            - 'positions' (torch.Tensor): Position encodings for all tokens, including generated ones.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If `positions` shape does not match `input_ids` shape.\n",
    "\n",
    "    Example:\n",
    "        output = mdgen(\n",
    "            model=my_model,\n",
    "            input_ids=torch.tensor([[1, 2, 3]]),\n",
    "            mask=torch.ones(1, 3, 3),\n",
    "            gen_len=5,\n",
    "            n_branch=2,\n",
    "            greedy=True\n",
    "        )\n",
    "        print(output['branch_ids'])\n",
    "    \"\"\"\n",
    "\n",
    "    past_len=0 if past_key_values is None else past_key_values.get_seq_length()\n",
    "\n",
    "    if positions is not None:\n",
    "        assert input_ids.shape == positions.shape,\"positions.shape must match input_ids.shape\"\n",
    "    #assert mask.shape[2]==input_ids.shape[1],\"length of attn mask must match input length\"\n",
    "\n",
    "\n",
    "    batch_size,ctx_len=input_ids.shape\n",
    "    \n",
    "    # every cycle we add n_branch more tokens, so the end of the 4D attention mask is a diagonal. Create here and reuse below\n",
    "    gen_mask = torch.where(torch.eye(n_branch) == 1, torch.tensor(0.0), torch.tensor(float('-inf'))).unsqueeze(0).unsqueeze(0).to(model.device)\n",
    "\n",
    "    # position information of the initial context input_ids. If None assume 0..ctx_len\n",
    "    if positions is None:\n",
    "        positions=torch.arange(ctx_len,dtype=torch.int).unsqueeze(0)\n",
    "    positions=positions.to(model.device)\n",
    "    position_history=copy.copy(positions)\n",
    "\n",
    "\n",
    "    # if branch location is not specified, assume all branches start at the end of the context\n",
    "    if branch_locations is None:\n",
    "        branch_locations=[ctx_len-1]*n_branch\n",
    "        \n",
    "    assert all(bl>past_len for bl in branch_locations),\"Branches must start with new input_ids, not from past_key_values.\"\n",
    "\n",
    "    # the position encoding of the first generated token is just after the branch location position encoding\n",
    "    tmp=[int(positions[0,x]) for x in branch_locations] \n",
    "    gen_positions=torch.tensor(tmp).unsqueeze(0).to(model.device)\n",
    "\n",
    "\n",
    "    # we will accumulate the generated tokens into output_ids\n",
    "    output_ids=torch.empty((batch_size,0),dtype=torch.int).to(model.device)\n",
    "\n",
    "    # move remaining tensors to model.device\n",
    "    mask=mask.to(model.device)\n",
    "    input_ids=input_ids.to(model.device)\n",
    "    initial_length=input_ids.shape[1]\n",
    "    pkv=past_key_values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # first step is to prefill the context and generate pkv\n",
    "        print(f\"{past_len=} {input_ids.shape=} {positions.shape=} {mask.shape=} {input_ids[:,past_len:].shape=} {positions[:,past_len:].shape=}\")\n",
    "        print(f\"{input_ids.device=} {positions.device=} {mask.device=} \")\n",
    "        output=model.forward(input_ids=input_ids[:,past_len:],position_ids=positions[:,past_len:] ,attention_mask=mask, use_cache=True,past_key_values=pkv)\n",
    "        pkv = output.past_key_values\n",
    "\n",
    "        # get logits from the locations where the branches fork\n",
    "        branch_locations=torch.tensor(branch_locations,dtype=torch.int)\n",
    "        \n",
    "        # branch locations are relative to full input sequence,\n",
    "        # so we subtrack the pkv length \n",
    "        logits=output['logits'][:,branch_locations-past_len,:]\n",
    "        print(f\"{mask.shape=} {branch_locations=}\")\n",
    "        mask = mask[:,:,branch_locations-past_len,:]\n",
    "\n",
    "        for i in range(gen_len):\n",
    "            # select tokens, greedy or not\n",
    "            next_token_probs = F.softmax(logits / 0.7, dim=-1)\n",
    "            if greedy:\n",
    "                tokens = torch.argmax(next_token_probs,dim=-1)\n",
    "            else:\n",
    "                samples = torch.multinomial(next_token_probs.view(-1,next_token_probs.shape[-1]), num_samples=1, replacement=True).view(batch_size,n_branch)\n",
    "                tokens = samples.squeeze(-1)\n",
    "\n",
    "            # save the generated tokens\n",
    "            output_ids=torch.cat([output_ids,tokens],dim=-1)\n",
    "            mask=torch.cat([mask,gen_mask],dim=-1)\n",
    "\n",
    "            # Generate n_branch new tokens.\n",
    "            print(f\"{tokens.shape=} {gen_positions.shape=} {mask.shape=} {pkv.get_seq_length()=}\")\n",
    "            output=model.forward(input_ids=tokens,position_ids=gen_positions ,attention_mask=mask, past_key_values=pkv, use_cache=True)\n",
    "            logits=output['logits']\n",
    "            pkv = output['past_key_values'] \n",
    "\n",
    "            # increment the position information for the next token\n",
    "            gen_positions+=1\n",
    "\n",
    "            position_history=torch.cat([position_history,gen_positions],dim=-1)\n",
    "\n",
    "    # restruture the results to have n_branch sequences\n",
    "    branch_ids=output_ids.view(-1,n_branch,1).permute(2,1,0).squeeze(-1)\n",
    "    full_ids=torch.cat([input_ids,output_ids],dim=-1)\n",
    "    return {'branch_ids':branch_ids,'mask':mask,'output_ids':output_ids,'input_ids':full_ids,'initial_length':initial_length,'positions':position_history,'past_key_values':pkv}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpful utilities\n",
    "def print_branches(branch_ids):\n",
    "    branch_ids=branch_ids.cpu()\n",
    "    for sidx,branches in enumerate(branch_ids):\n",
    "        for bidx,branch_ids in enumerate(branches):\n",
    "            ids=branch_ids\n",
    "            print(f\"{sidx}.{bidx}: {''.join(tokenizer.batch_decode(ids, skip_special_tokens=True))}\")\n",
    "\n",
    "def print_mask(mask):\n",
    "    for i in range(mask.shape[2]):\n",
    "        for j in range(mask.shape[3]):\n",
    "            print('*' if mask[0,0,i,j]==0. else '.',end=\"\")\n",
    "        print()\n",
    "\n",
    "def print_full(output):\n",
    "    full_ids=torch.cat([output['input_ids'],output['output_ids']],dim=-1)\n",
    "    # print(f\"{full_ids=}\")\n",
    "    # print(''.join(tokenizer.batch_decode(full_ids, skip_special_tokens=True)))\n",
    "    mask=output['mask']\n",
    "    for b in range(mask.shape[2]):\n",
    "        branch_full_ids=[]\n",
    "        for p in range(mask.shape[3]):\n",
    "            if mask[0,0,b,p] == 0.0:\n",
    "                branch_full_ids.append(int(full_ids[0,p]))\n",
    "        print(f\"{b}:{''.join(tokenizer.batch_decode(branch_full_ids, skip_special_tokens=True))}\")\n",
    "        \n",
    "\n",
    "def print_args(input_ids=None,positions=None,mask=None,branch_locations=None):\n",
    "    print()\n",
    "    print(\"Arguments:\")\n",
    "    print(f\"{input_ids.shape=}\")\n",
    "    if positions is not None:\n",
    "        print(f\"{positions=}\")\n",
    "    if branch_locations is not None:\n",
    "        print(f\"{branch_locations=}\")\n",
    "    print()\n",
    "    if mask is not None:\n",
    "        print_mask(mask)\n",
    "    print()\n",
    "\n",
    "def print_results(output):\n",
    "    print()\n",
    "    print(\"Results\")\n",
    "    print(\"raw\")\n",
    "    print(f\"{''.join(tokenizer.batch_decode(output['output_ids'], skip_special_tokens=True))}\")\n",
    "    print()\n",
    "    print(\"Reformated\")\n",
    "    print_full(output)\n",
    "    print()\n",
    "    print(f\"positions {output['positions']}\")\n",
    "    print()\n",
    "    print_mask(output['mask'])\n",
    "    print()\n",
    "    \n",
    "def strmask(*args):\n",
    "    n_branch=len(args)\n",
    "    seq_len=len(args[0])\n",
    "    ret=torch.full((n_branch,seq_len),fill_value=float('-inf'))\n",
    "\n",
    "    for b,arg in enumerate(args):\n",
    "        for i,v in enumerate(arg):\n",
    "            if v=='1' or v=='*':\n",
    "                ret[b,i]=0\n",
    "    return ret.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "def lut_attn(n):\n",
    "    ''''\n",
    "\n",
    "    Returns a lower triangle array with dimensions and values suitable for an attention mask\n",
    "    dimension: [1,1,n,n]\n",
    "    values: 0 in lower triangle and diagonal\n",
    "            -inf in upper triangle\n",
    "    \n",
    "    '''\n",
    "    return torch.where(torch.tril(torch.ones(n,n)) == 1, torch.tensor(0.0), torch.tensor(float('-inf'))).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "model_name=\"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,padding_side='left')\n",
    "tokenizer.pad_token_id=tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)#,attn_implementation=\"flex_attention\")\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 5])\n",
      "\n",
      "*....\n",
      "**...\n",
      "***..\n",
      "****.\n",
      "*****\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m mask\u001b[38;5;241m=\u001b[39mlut_attn(input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      6\u001b[0m print_args(input_ids,mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m----> 8\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[43mmdgen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_branch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mgreedy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m print_results(output)\n",
      "Cell \u001b[0;32mIn[3], line 69\u001b[0m, in \u001b[0;36mmdgen\u001b[0;34m(model, input_ids, positions, mask, gen_len, n_branch, greedy, branch_locations, past_key_values)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m branch_locations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     branch_locations\u001b[38;5;241m=\u001b[39m[ctx_len\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mn_branch\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(\u001b[43mbranch_locations\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43mpast_len\u001b[49m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBranches must start with new input_ids, not from past_key_values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# the position encoding of the first generated token is just after the branch location position encoding\u001b[39;00m\n\u001b[1;32m     72\u001b[0m tmp\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mint\u001b[39m(positions[\u001b[38;5;241m0\u001b[39m,x]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m branch_locations] \n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# simple beam generation\n",
    "input_ids=tokenizer(\"Once upon a time\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "\n",
    "print_args(input_ids,mask=mask)\n",
    "\n",
    "output=mdgen(model, input_ids,positions=None,mask=mask,n_branch=5,greedy=False)\n",
    "\n",
    "print_results(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DynamicCache\n",
    "# # simple beam generation\n",
    "# input_ids=tokenizer(\"Once upon a time\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "\n",
    "# mask=lut_attn(input_ids.shape[1])\n",
    "\n",
    "\n",
    "# # print_args(input_ids,mask=mask)\n",
    "\n",
    "# n_branch=5\n",
    "# print(f\"{input_ids.shape=}\")\n",
    "# output=mdgen(model, input_ids,positions=None,mask=mask,n_branch=n_branch,greedy=False)\n",
    "# print(f\"{input_ids.shape=}\")\n",
    "# print_results(output)\n",
    "\n",
    "# selected_branch=2\n",
    "# input_len=input_ids.shape[1]\n",
    "# gen_len=output['output_ids'].shape[1]\n",
    "# output_indexes=torch.arange(input_len+selected_branch,gen_len,n_branch,dtype=torch.int)\n",
    "# indexes=torch.cat([torch.arange(input_len,dtype=torch.int),output_indexes])\n",
    "# print(f\"{indexes=}\")\n",
    "\n",
    "# pkv=output['past_key_values']\n",
    "# print(f\"{len(pkv)=} {pkv.get_seq_length()=} {pkv.get_max_cache_shape()=} {output['output_ids'].shape=}\")\n",
    "\n",
    "# lpkv=pkv.to_legacy_cache()\n",
    "# npkv=[]\n",
    "# for (k,v) in lpkv:\n",
    "#     npkv.append((k[:,:,indexes,:],v[:,:,indexes,:]))\n",
    "# positions=output['positions'][:,indexes]\n",
    "# output_ids=output['output_ids'][:,output_indexes]\n",
    "# #mask\n",
    "# print(type(positions))\n",
    "# npkv=DynamicCache.from_legacy_cache(tuple(npkv))\n",
    "\n",
    "# print(f\"{len(npkv)=} {npkv.get_seq_length()=} {npkv.get_max_cache_shape()=} {output['output_ids'].shape=}\")\n",
    "\n",
    "# output=model.forward(input_ids=tokens, past_key_values=pkv, use_cache=True)\n",
    "# logits=output['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_len=0 input_ids.shape=torch.Size([1, 5]) positions.shape=torch.Size([1, 5]) mask.shape=torch.Size([1, 1, 5, 5]) input_ids[:,past_len:].shape=torch.Size([1, 5]) positions[:,past_len:].shape=torch.Size([1, 5])\n",
      "input_ids.device=device(type='cuda', index=0) positions.device=device(type='cuda', index=0) mask.device=device(type='cuda', index=0) \n",
      "mask.shape=torch.Size([1, 1, 5, 5]) branch_locations=tensor([4, 4, 4], dtype=torch.int32)\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 8]) pkv.get_seq_length()=5\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 11]) pkv.get_seq_length()=8\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 14]) pkv.get_seq_length()=11\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 17]) pkv.get_seq_length()=14\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 20]) pkv.get_seq_length()=17\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 23]) pkv.get_seq_length()=20\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 26]) pkv.get_seq_length()=23\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 29]) pkv.get_seq_length()=26\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 32]) pkv.get_seq_length()=29\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 35]) pkv.get_seq_length()=32\n",
      "\n",
      "Results\n",
      "raw\n",
      ",,, there back there was in lived a the a mouse early small,  village a199 that man0 was,s called and, “\n",
      "\n",
      "Reformated\n",
      "0:Once upon a time, there was a mouse, a man, and\n",
      "1:Once upon a time, back in the early 1990s,\n",
      "2:Once upon a time, there lived a small village that was called “\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,\n",
      "          9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14]],\n",
      "       device='cuda:0')\n",
      "\n",
      "******..*..*..*..*..*..*..*..*..*..\n",
      "*****.*..*..*..*..*..*..*..*..*..*.\n",
      "*****..*..*..*..*..*..*..*..*..*..*\n",
      "\n",
      "o_positions.shape=torch.Size([1, 35]) o_positions=tensor([[ 0,  1,  2,  3,  4,  5,  5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,\n",
      "          9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14]],\n",
      "       device='cuda:0')\n",
      "o_output_ids.shape=torch.Size([1, 30]) o_output_ids=tensor([[   11,    11,    11,  1070,  1203,  1070,   574,   304, 12439,   264,\n",
      "           279,   264,  8814,  4216,  2678,    11,   220, 14458,   264,  2550,\n",
      "           430,   893,    15,   574,    11,    82,  2663,   323,    11,  1054]],\n",
      "       device='cuda:0')\n",
      "o_input_ids.shape=torch.Size([1, 35]) o_input_ids=tensor([[128000,  12805,   5304,    264,    892,     11,     11,     11,   1070,\n",
      "           1203,   1070,    574,    304,  12439,    264,    279,    264,   8814,\n",
      "           4216,   2678,     11,    220,  14458,    264,   2550,    430,    893,\n",
      "             15,    574,     11,     82,   2663,    323,     11,   1054]],\n",
      "       device='cuda:0')\n",
      "o_mask.shape=torch.Size([1, 1, 3, 35])\n",
      "******..*..*..*..*..*..*..*..*..*..\n",
      "*****.*..*..*..*..*..*..*..*..*..*.\n",
      "*****..*..*..*..*..*..*..*..*..*..*\n",
      "o_initial_len=5 o_input_ids_len=35\n",
      "input_indexes=tensor([ 0,  1,  2,  3,  4,  6,  9, 12, 15, 18, 21, 24, 27, 30, 33])\n",
      "o_input_ids.shape[1]- o_initial_len=30  o_initial_len=5o_input_ids.shape[1]=35\n",
      "selected_len=10\n",
      "input2_ids=tensor([[128000,  12805,   5304,    264,    892,     11,   1203,    304,    279,\n",
      "           4216,    220,   2550,     15,     82,     11]], device='cuda:0')\n",
      "Once upon a time, back in the early 1990s,\n",
      "position2_ids=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]],\n",
      "       device='cuda:0')\n",
      "******.........\n",
      "*******........\n",
      "********.......\n",
      "*********......\n",
      "**********.....\n",
      "***********....\n",
      "************...\n",
      "*************..\n",
      "**************.\n",
      "***************\n",
      "input2_ids.shape=torch.Size([1, 15]) position2_ids.shape=torch.Size([1, 15]) mask2.shape=torch.Size([1, 1, 10, 15]) pkv.get_seq_length()=5\n",
      "past_len=5 input_ids.shape=torch.Size([1, 15]) positions.shape=torch.Size([1, 15]) mask.shape=torch.Size([1, 1, 10, 15]) input_ids[:,past_len:].shape=torch.Size([1, 10]) positions[:,past_len:].shape=torch.Size([1, 10])\n",
      "input_ids.device=device(type='cuda', index=0) positions.device=device(type='cuda', index=0) mask.device=device(type='cuda', index=0) \n",
      "mask.shape=torch.Size([1, 1, 10, 15]) branch_locations=tensor([14, 14, 14], dtype=torch.int32)\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 18]) pkv.get_seq_length()=15\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 21]) pkv.get_seq_length()=18\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 24]) pkv.get_seq_length()=21\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 27]) pkv.get_seq_length()=24\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 30]) pkv.get_seq_length()=27\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 33]) pkv.get_seq_length()=30\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 36]) pkv.get_seq_length()=33\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 39]) pkv.get_seq_length()=36\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 42]) pkv.get_seq_length()=39\n",
      "tokens.shape=torch.Size([1, 3]) gen_positions.shape=torch.Size([1, 3]) mask.shape=torch.Size([1, 1, 3, 45]) pkv.get_seq_length()=42\n",
      "\n",
      "Results\n",
      "raw\n",
      " a there a certain was novel American a called comedy band The actor called G of Sexolem the Pist and timeols the played. J a Theyinn\n",
      "\n",
      "Reformated\n",
      "0:Once upon a time, back in the early 1990s, a certain American comedy actor of the time played a\n",
      "1:Once upon a time, back in the early 1990s, there was a band called Sex Pistols. They\n",
      "2:Once upon a time, back in the early 1990s, a novel called The Golem and the Jinn\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 15, 15,\n",
      "         16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21,\n",
      "         22, 22, 22, 23, 23, 23, 24, 24, 24]], device='cuda:0')\n",
      "\n",
      "****************..*..*..*..*..*..*..*..*..*..\n",
      "***************.*..*..*..*..*..*..*..*..*..*.\n",
      "***************..*..*..*..*..*..*..*..*..*..*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consolidation take 2\n",
    "from transformers import DynamicCache\n",
    "# simple beam generation\n",
    "input_ids=tokenizer(\"Once upon a time\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "\n",
    "\n",
    "print_args(input_ids,mask=mask)\n",
    "\n",
    "input_len=input_ids.shape[1]\n",
    "n_branch=3\n",
    "output=mdgen(model, input_ids,positions=None,mask=mask,n_branch=n_branch,greedy=False)\n",
    "print_results(output)\n",
    "selected_branch=1\n",
    "\n",
    "pkv=output['past_key_values']\n",
    "o_positions=output['positions']\n",
    "o_mask=output['mask']\n",
    "o_output_ids=output['output_ids']\n",
    "o_input_ids=output['input_ids']\n",
    "o_initial_len=output['initial_length']\n",
    "print(f\"{o_positions.shape=} {o_positions=}\")\n",
    "print(f\"{o_output_ids.shape=} {o_output_ids=}\")\n",
    "print(f\"{o_input_ids.shape=} {o_input_ids=}\")\n",
    "print(f\"{o_mask.shape=}\")\n",
    "print_mask(o_mask)\n",
    "o_input_ids_len=o_input_ids.shape[1]\n",
    "print(f\"{o_initial_len=} {o_input_ids_len=}\")\n",
    "input_indexes=torch.cat([torch.arange(o_initial_len),torch.arange(o_initial_len+selected_branch,o_input_ids_len+1,n_branch,dtype=torch.int)],dim=-1)\n",
    "print(f\"{input_indexes=}\")\n",
    "\n",
    "input2_ids=o_input_ids[:,input_indexes]\n",
    "position2_ids=o_positions[:,input_indexes]\n",
    "print(f\"{o_input_ids.shape[1]- o_initial_len=} { o_initial_len=}{o_input_ids.shape[1]=}\")\n",
    "selected_len=(o_input_ids.shape[1]- o_initial_len)//n_branch\n",
    "print(f\"{selected_len=}\")\n",
    "mask2=o_mask[:,:,selected_branch,input_indexes[:o_initial_len]].repeat([1,1,selected_len,1])\n",
    "mask2=torch.cat([mask2,lut_attn(selected_len).to(model.device)],dim=-1)\n",
    "print(f\"{input2_ids=}\")\n",
    "print(f\"{''.join(tokenizer.batch_decode(input2_ids, skip_special_tokens=True))}\")\n",
    "\n",
    "print(f\"{position2_ids=}\")\n",
    "print_mask(mask2)\n",
    "\n",
    "\n",
    "pkv.crop(input_len)\n",
    "\n",
    "print(f\"{input2_ids.shape=} {position2_ids.shape=} {mask2.shape=} {pkv.get_seq_length()=}\")\n",
    "\n",
    "output=mdgen(model, input2_ids,positions=position2_ids,mask=mask2,n_branch=n_branch,greedy=False,past_key_values=pkv)\n",
    "\n",
    "print_results(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 31])\n",
      "positions=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 17, 18, 19, 20, 21, 22, 23]])\n",
      "\n",
      "*..............................\n",
      "**.............................\n",
      "***............................\n",
      "****...........................\n",
      "*****..........................\n",
      "******.........................\n",
      "*******........................\n",
      "********.......................\n",
      "*********......................\n",
      "**********.....................\n",
      "***********....................\n",
      "************...................\n",
      "*************..................\n",
      "**************.................\n",
      "***************................\n",
      "****************...............\n",
      "*****************..............\n",
      "******************.............\n",
      "*******************............\n",
      "********************...........\n",
      "*********************..........\n",
      "**********************.........\n",
      "***********************........\n",
      "************************.......\n",
      "*****************.......*......\n",
      "*****************.......**.....\n",
      "*****************.......***....\n",
      "*****************.......****...\n",
      "*****************.......*****..\n",
      "*****************.......******.\n",
      "*****************.......*******\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      " The The answer answer is is purple green.. The The bike grass is is purple green..\n",
      "\n",
      "Reformated\n",
      "0:The house is red. The grass is green. The bike is purple. What color is the bike? The answer is purple. The bike is purple.\n",
      "1:The house is red. The grass is green. The bike is purple. What color is the grass? The answer is green. The grass is green.\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 25, 26,\n",
      "         26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32, 32, 33, 33]],\n",
      "       device='cuda:0')\n",
      "\n",
      "************************.......*.*.*.*.*.*.*.*.*.*.\n",
      "*****************.......*******.*.*.*.*.*.*.*.*.*.*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multi-question\n",
    "context_ids=tokenizer(\"The house is red. The grass is green. The bike is purple. \", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device) \n",
    "question1_ids=tokenizer(\"What color is the bike?\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "question2_ids=tokenizer(\"What color is the grass?\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "context_len=context_ids.shape[1]\n",
    "question1_len=question1_ids.shape[1]\n",
    "question2_len=question2_ids.shape[1]\n",
    "\n",
    "input_ids=torch.cat([context_ids,question1_ids,question2_ids],dim=-1)\n",
    "\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "# mask out the first question from the view of the second question\n",
    "mask[:,:,context_len+question1_len:,context_len:context_len+question1_len]=float('-inf')\n",
    "\n",
    "positions=torch.cat([torch.arange(context_len+question1_len),torch.arange(context_len,context_len+question2_len)]).unsqueeze(0)\n",
    "branch_locations=[context_len+question1_len-1,context_len+question1_len+question2_len-1]\n",
    "\n",
    "print_args(input_ids,positions,mask)\n",
    "\n",
    "output=mdgen(model, input_ids,positions=positions,mask=mask,branch_locations=branch_locations,greedy=True)\n",
    "\n",
    "print_results(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context1_len=7 context2_len=12 question1_len=7 question2_len=7\n",
      "positions=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18,  7,  8,  9, 10, 11, 12, 13, 19, 20, 21, 22, 23, 24, 25]])\n",
      "input_ids.shape=torch.Size([1, 33]) positions.shape=torch.Size([1, 33])\n",
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 33])\n",
      "positions=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18,  7,  8,  9, 10, 11, 12, 13, 19, 20, 21, 22, 23, 24, 25]])\n",
      "\n",
      "*................................\n",
      "**...............................\n",
      "***..............................\n",
      "****.............................\n",
      "*****............................\n",
      "******...........................\n",
      "*******..........................\n",
      "********.........................\n",
      "*********........................\n",
      "**********.......................\n",
      "***********......................\n",
      "************.....................\n",
      "*************....................\n",
      "**************...................\n",
      "***************..................\n",
      "****************.................\n",
      "*****************................\n",
      "******************...............\n",
      "*******************..............\n",
      "*******............*.............\n",
      "*******............**............\n",
      "*******............***...........\n",
      "*******............****..........\n",
      "*******............*****.........\n",
      "*******............******........\n",
      "*******............*******.......\n",
      "*******************.......*......\n",
      "*******************.......**.....\n",
      "*******************.......***....\n",
      "*******************.......****...\n",
      "*******************.......*****..\n",
      "*******************.......******.\n",
      "*******************.......*******\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results\n",
      "raw\n",
      " The The house answer was is red blue..  The2 house. is What red color.\n",
      "\n",
      "Reformated\n",
      "0:The house was red. What color is the bike? The house was red. 2. What color\n",
      "1:The house was red. The grass was green. The bike was blue. What color is the bike? The answer is blue. The house is red.\n",
      "\n",
      "positions tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18,  7,  8,  9, 10, 11, 12, 13, 19, 20, 21, 22, 23, 24, 25, 14, 26, 15,\n",
      "         27, 16, 28, 17, 29, 18, 30, 19, 31, 20, 32, 21, 33, 22, 34, 23, 35]],\n",
      "       device='cuda:0')\n",
      "\n",
      "*******............*******.......*.*.*.*.*.*.*.*.*.*.\n",
      "*******************.......*******.*.*.*.*.*.*.*.*.*.*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Writing in the margins\n",
    "context1_ids=tokenizer(\"The house was red. \", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "context2_ids=tokenizer(\"The grass was green. The bike was blue. \", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)  \n",
    "question1_ids=tokenizer(\"What color is the bike?\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "question2_ids=tokenizer(\"What color is the bike?\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "context1_len=context1_ids.shape[1]\n",
    "context2_len=context2_ids.shape[1]\n",
    "question1_len=question1_ids.shape[1]\n",
    "question2_len=question2_ids.shape[1]\n",
    "print(f\"{context1_len=} {context2_len=} {question1_len=} {question2_len=}\")\n",
    "\n",
    "input_ids=torch.cat([context1_ids,context2_ids,question1_ids,question2_ids],dim=-1)\n",
    "\n",
    "# mask out the second context from the first question, and the first question from the view of the second question\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "mask[:,:,context1_len+context2_len:context1_len+context2_len+question1_len,context1_len:context1_len+context2_len]=float('-inf')\n",
    "mask[:,:,context1_len+context2_len+question1_len:,context1_len+context2_len:context1_len+context2_len+question1_len]=float('-inf')\n",
    "\n",
    "\n",
    "# make question 1 follow context1 and question 2 follow context2 \n",
    "positions=torch.cat([\n",
    "    torch.arange(context1_len+context2_len),\n",
    "    torch.arange(context1_len,context1_len+question1_len),\n",
    "    torch.arange(context1_len+context2_len,context1_len+context2_len+question2_len)]).unsqueeze(0)\n",
    "\n",
    "print(f\"{positions=}\")\n",
    "print(f\"{input_ids.shape=} {positions.shape=}\")\n",
    "branch_locations=[context1_len+context2_len+question1_len-1,context1_len+context2_len+question1_len+question2_len-1]\n",
    "\n",
    "print_args(input_ids,positions,mask)\n",
    "\n",
    "output=mdgen(model, input_ids,positions=positions,mask=mask,branch_locations=branch_locations,greedy=True)\n",
    "\n",
    "print_results(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 6])\n",
      "\n",
      "*.....\n",
      "**....\n",
      "***...\n",
      "****..\n",
      "*****.\n",
      "******\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      " 2\n",
      "\n",
      "Reformated\n",
      "0:5 - 3 = 2\n",
      "\n",
      "positions tensor([[0, 1, 2, 3, 4, 5, 6, 7]], device='cuda:0')\n",
      "\n",
      "********\n",
      "\n",
      "0:5 - 3 = 2\n"
     ]
    }
   ],
   "source": [
    "# Teds example part 1\n",
    "input_ids=tokenizer(\"5 - 3 =\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "\n",
    "mask=lut_attn(input_ids.shape[1])\n",
    "\n",
    "print_args(input_ids,mask=mask)\n",
    "\n",
    "output=mdgen(model, input_ids,mask=mask,n_branch=1,gen_len=2,greedy=True)\n",
    "\n",
    "print_results(output)\n",
    "print_full(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_ids.cpu()=tensor([[128000,     20,    482,    220,     18,    284]])\n",
      "input_ids.cpu()=tensor([[128000,     20,    284,    482,    220,     18]])\n",
      "\n",
      "Arguments:\n",
      "input_ids.shape=torch.Size([1, 6])\n",
      "positions=tensor([[0, 1, 5, 2, 3, 4]], dtype=torch.int32)\n",
      "\n",
      "*.....\n",
      "**....\n",
      "******\n",
      "**.*..\n",
      "**.**.\n",
      "**.***\n",
      "\n",
      "\n",
      "Results\n",
      "raw\n",
      " 2\n",
      "\n",
      "Reformated\n",
      "0:5 = - 3 2\n",
      "\n",
      "positions tensor([[0, 1, 5, 2, 3, 4, 6, 7]], device='cuda:0')\n",
      "\n",
      "********\n",
      "\n",
      "0:5 = - 3 2\n"
     ]
    }
   ],
   "source": [
    "# Teds example part 2\n",
    "original_ids=tokenizer(\"5 - 3 =\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "print(f\"{original_ids.cpu()=}\")\n",
    "input_ids=tokenizer(\"5 = - 3\", return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(model.device)\n",
    "print(f\"{input_ids.cpu()=}\")\n",
    "\n",
    "\n",
    "mask=strmask(\"*.....\",\"**....\",\"******\",\"**.*..\",\"**.**.\",\"**.***\")\n",
    "\n",
    "order=torch.tensor([0, 1, 3, 4, 5, 2])\n",
    "\n",
    "positions=torch.tensor([[0, 1, 5, 2,3,4]],dtype=torch.int)\n",
    "branch_locations=[2]\n",
    "\n",
    "print_args(input_ids,mask=mask,positions=positions)\n",
    "\n",
    "output=mdgen(model, input_ids,positions=positions,mask=mask,branch_locations=branch_locations,n_branch=1,gen_len=2,greedy=True)\n",
    "\n",
    "print_results(output)\n",
    "print_full(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
